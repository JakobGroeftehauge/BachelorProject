{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference - Classification, BBox, Angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_file = 'list_of_img_in_val_set4.csv'\n",
    "place_to_store_results = 'Evaluations/something_else/'\n",
    "path_img_folder = '../../../03 Data/Simple Dataset/'\n",
    "accept_BB_threshold = 0.9\n",
    "\n",
    "model_folder = \"\"\n",
    "model_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "# set the modified tf session as backend in keras  \n",
    "#setup_gpu(gpu)  #NOTICE: enable when using paperspace server!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rect_to_point(rect):\n",
    "    x = rect[0]\n",
    "    y = rect[1]\n",
    "    w = rect[2]\n",
    "    h = rect[3]\n",
    "    x1 = x\n",
    "    y1 = y\n",
    "    x2 = x + w\n",
    "    y2 = y + h\n",
    "    \n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "def read_annotations_from_json(img_name):\n",
    "    with open(path_img_folder + img_name.strip('.png') + '.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        shapes_list = data['shapes']\n",
    "        bbox_list = []\n",
    "        angle_list = []\n",
    "        for annotation in shapes_list: \n",
    "            rect = cv2.boundingRect(np.float32(annotation['points']))\n",
    "            rot_rect = cv2.minAreaRect(np.float32(annotation['points']))\n",
    "            \n",
    "            annotation_list.append(convert_rect_to_point(rect))\n",
    "    return bbox_list, angle_list; \n",
    "\n",
    "\n",
    "def max_val(val1, val2):\n",
    "    if val1 > val2:\n",
    "        return val1\n",
    "    else:\n",
    "        return val2\n",
    "    \n",
    "def min_val(val1, val2):\n",
    "    if val1 > val2:\n",
    "        return val2\n",
    "    else:\n",
    "        return val1\n",
    "    \n",
    "    \n",
    "def filter_bounding_boxes(bounding_boxes, scores):\n",
    "    list_of_BB = []\n",
    "    for box, score in zip(bounding_boxes, scores):\n",
    "        if score < accept_BB_threshold: \n",
    "            break\n",
    "        list_of_BB.append(box)\n",
    "    return list_of_BB\n",
    "\n",
    "\n",
    "def area(BB):\n",
    "    width = abs(BB[0] - BB[2])\n",
    "    height = abs(BB[1] - BB[3])\n",
    "    return height * width\n",
    "\n",
    "def intersection(BB1, BB2):\n",
    "    # find coordiantes of intersection rectangle \n",
    "    (x1, y1, x2, y2) = BB1\n",
    "    (x3, y3, x4, y4) = BB2\n",
    "    if x1 > x4 or x3 > x2 or y3 > y2 or y1 > y4:\n",
    "        return 0\n",
    "    x5 = max_val(x1, x3);\n",
    "    y5 = max_val(y1, y3);\n",
    "    x6 = min_val(x2, x4);\n",
    "    y6 = min_val(y2, y4);  \n",
    "    BB = (x5, y5, x6, y6)\n",
    "    # TODO: check if no intersection exists\n",
    "    return area(BB)\n",
    "    \n",
    "def union(BB1, BB2): \n",
    "    return area(BB1) + area(BB2) - intersection(BB1, BB2)\n",
    "\n",
    "def evaluate_predictions(annotations, preds, IOU_thres):\n",
    "    predictions = copy.deepcopy(preds)\n",
    "    false_neg = 0\n",
    "    for annotation in annotations: \n",
    "        #annotation = convert_rect_to_point(anno)\n",
    "        max_IOU = 0\n",
    "        for i in range(len(predictions)): \n",
    "            #print('Annotation: ', annotation)\n",
    "            #print('pred candidate: ', predictions[i])\n",
    "            if intersection(annotation, predictions[i]) > 0: #convert_rect_to_point only for tests\n",
    "                IOU = intersection(annotation, predictions[i])/union(annotation, predictions[i])\n",
    "                #print(IOU)  \n",
    "                if(IOU > max_IOU):\n",
    "                    max_IOU_index = i\n",
    "                    max_IOU = IOU\n",
    "        if max_IOU > IOU_thres:\n",
    "            # remove prediction from list\n",
    "            predictions.pop(max_IOU_index)\n",
    "        else:\n",
    "            false_neg = false_neg + 1\n",
    "    \n",
    "    false_pos = len(predictions)\n",
    "    true_pos = len(preds) - len(predictions)\n",
    "    return (false_neg, false_pos, true_pos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "model_path = os.path.join('..','..','Create-CSV-dataset', 'snapshots', 'resnet50_csv_25.h5');\n",
    "model = models.load_model(model_path, backbone_name='resnet50');\n",
    "\n",
    "# If model is not converted to inference model, use line below: \n",
    "model = models.convert_model(model);\n",
    "\n",
    "# Mapping of model output and classes\n",
    "labels_to_names = {0: 'Brick'};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "file = open(file_location)\n",
    "file_paths = list(file)  \n",
    "\n",
    "bbox_prediction_list = [] \n",
    "angle_prediction_list = []\n",
    "\n",
    "bbox_annotation_list = []\n",
    "angle_annotation_list = []\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "for path in file_paths:\n",
    "    image = read_image_bgr(path_img_folder + path.strip('\\n'))\n",
    "\n",
    "    # create copy to draw on \n",
    "    draw = image.copy()\n",
    "    draw2 = image.copy()\n",
    "    #draw = cv2.cvtColor(draw, cv2.COLhttp://cocodataset.org/#detection-evalOR_BGR2RGB)\n",
    "    \n",
    "    # preprocess image \n",
    "    # TODOD: check if preprocess_image convert the image to RGB format\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    \n",
    "    # process image \n",
    "    boxes, scores, labels, angles = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    \n",
    "    # print detections\n",
    "    for box, score, label, angles in zip(boxes[0], scores[0], labels[0], angles[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < accept_BB_threshold:\n",
    "            break\n",
    "\n",
    "        color = label_color(label)\n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "        draw_vector(draw, angles[0], angles[1], box)\n",
    "        draw_caption(draw2, b, caption)\n",
    "        draw_vector(draw2, angles[0], angles[1], box)\n",
    "    \n",
    "    cv2.addWeighted(draw, alpha, draw2, 1 - alpha,0, draw)\n",
    "    # save image \n",
    "    #cv2.imwrite(place_to_store_results + path.strip('\\n'), draw)\n",
    "    \n",
    "    # load json file containing annotations\n",
    "    bbox, angle = read_annotations_from_json(path.strip('\\n'))\n",
    "    \n",
    "    bbox_annotation_list.append(bbox)\n",
    "    angle_annotation_list.append(angle)\n",
    "    \n",
    "    \n",
    "    # remove bounding boxes with a classification score below accept_BB_threshold. \n",
    "    prediction_list.append(filter_bounding_boxes(boxes[0], scores[0]))\n",
    "    \n",
    "print(annotation_list)\n",
    "print(prediction_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU_thres = np.arange(0.5, 1, 0.05).tolist()\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for thres in IOU_thres: \n",
    "    print('Threshold: ', thres)\n",
    "    total_false_positive = 0\n",
    "    total_true_positive = 0\n",
    "    total_false_negative = 0\n",
    "    for i in range(len(annotation_list)):\n",
    "        #calculate intersection and union of two bounding boxes\n",
    "        (false_neg, false_pos, true_pos) = evaluate_predictions(annotation_list[i], prediction_list[i], thres)\n",
    "        #results = evaluate_predictions(annotations, annotations)\n",
    "        total_false_negative = total_false_negative + false_neg\n",
    "        total_false_positive = total_false_positive + false_pos\n",
    "        total_true_positive  = total_true_positive  + true_pos\n",
    "        \n",
    "    # Calculate precision, recall and F1 score \n",
    "    precision = total_true_positive / (total_true_positive + total_false_positive)\n",
    "    precision_list.append(precision)\n",
    "    recall = total_true_positive / (total_true_positive + total_false_negative)\n",
    "    recall_list.append(recall)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) \n",
    "    f1_list.append(f1)\n",
    "    \n",
    "    # print result\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('f1: ', f1)\n",
    "    \n",
    "print(precision_list)\n",
    "print(recall_list)\n",
    "print(f1_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "plt.plot(IOU_thres, precision_list)\n",
    "plt.plot(IOU_thres, recall_list)\n",
    "plt.plot(IOU_thres, f1_list)\n",
    "plt.legend(['Precision', 'Recall', 'F1'])\n",
    "plt.title('AP score, RetinaNet, Validation set')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('IOU Threshold')\n",
    "\n",
    "\n",
    "average_precision = np.average(precision_list)\n",
    "average_recall = np.average(recall_list)\n",
    "average_f1 = np.average(f1_list)\n",
    "\n",
    "print('Avg. precision:', average_precision)\n",
    "print('Avg. recall:   ', average_recall)\n",
    "print('Avg. F1:       ', average_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
