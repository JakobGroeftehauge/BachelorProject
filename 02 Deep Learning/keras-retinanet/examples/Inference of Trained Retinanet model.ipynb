{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of Trained Retinanet model \n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "import json\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "#setup_gpu(gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colorIMG_52.png\\n', 'colorIMG_42.png\\n', 'colorIMG_103.png\\n', 'colorIMG_99.png\\n', 'colorIMG_166.png\\n', 'colorIMG_27.png\\n', 'colorIMG_132.png\\n', 'colorIMG_120.png\\n', 'colorIMG_34.png\\n', 'colorIMG_55.png\\n', 'colorIMG_119.png\\n', 'colorIMG_29.png\\n', 'colorIMG_128.png\\n', 'colorIMG_63.png\\n', 'colorIMG_170.png\\n', 'colorIMG_109.png\\n', 'colorIMG_149.png\\n', 'colorIMG_190.png\\n', 'colorIMG_32.png\\n', 'colorIMG_126.png\\n', 'colorIMG_171.png\\n', 'colorIMG_12.png\\n', 'colorIMG_57.png\\n', 'colorIMG_121.png\\n', 'colorIMG_145.png\\n', 'colorIMG_89.png\\n', 'colorIMG_105.png\\n', 'colorIMG_198.png\\n', 'colorIMG_65.png\\n', 'colorIMG_113.png\\n', 'colorIMG_66.png\\n', 'colorIMG_191.png\\n', 'colorIMG_24.png\\n', 'colorIMG_44.png\\n', 'colorIMG_14.png\\n', 'colorIMG_194.png\\n', 'colorIMG_61.png\\n', 'colorIMG_138.png\\n', 'colorIMG_144.png\\n', 'colorIMG_183.png\\n', 'colorIMG_7.png\\n', 'colorIMG_73.png\\n', 'colorIMG_67.png\\n', 'colorIMG_25.png\\n', 'colorIMG_117.png\\n', 'colorIMG_169.png\\n', 'colorIMG_31.png\\n', 'colorIMG_150.png\\n', 'colorIMG_178.png\\n', 'colorIMG_77.png\\n', 'colorIMG_163.png\\n', 'colorIMG_41.png\\n', 'colorIMG_130.png\\n', 'colorIMG_51.png\\n', 'colorIMG_22.png\\n', 'colorIMG_13.png\\n', 'colorIMG_36.png\\n', 'colorIMG_115.png\\n', 'colorIMG_124.png\\n', 'colorIMG_133.png\\n', 'colorIMG_0.png\\n', 'colorIMG_153.png\\n', 'colorIMG_19.png\\n', 'colorIMG_186.png\\n', 'colorIMG_177.png\\n', 'colorIMG_47.png\\n', 'colorIMG_168.png\\n', 'colorIMG_68.png\\n', 'colorIMG_180.png\\n', 'colorIMG_125.png\\n', 'colorIMG_201.png\\n', 'colorIMG_107.png\\n', 'colorIMG_21.png\\n', 'colorIMG_151.png\\n', 'colorIMG_72.png\\n', 'colorIMG_93.png\\n', 'colorIMG_146.png\\n', 'colorIMG_88.png\\n', 'colorIMG_33.png\\n', 'colorIMG_100.png\\n', 'colorIMG_164.png\\n', 'colorIMG_131.png\\n', 'colorIMG_37.png\\n', 'colorIMG_5.png\\n', 'colorIMG_40.png\\n', 'colorIMG_18.png\\n', 'colorIMG_176.png\\n', 'colorIMG_3.png\\n', 'colorIMG_6.png\\n', 'colorIMG_50.png\\n', 'colorIMG_26.png\\n', 'colorIMG_158.png\\n', 'colorIMG_161.png\\n', 'colorIMG_97.png\\n', 'colorIMG_15.png\\n', 'colorIMG_43.png\\n', 'colorIMG_83.png\\n', 'colorIMG_17.png\\n', 'colorIMG_192.png\\n', 'colorIMG_185.png\\n', 'colorIMG_48.png\\n', 'colorIMG_114.png\\n', 'colorIMG_76.png\\n', 'colorIMG_140.png\\n', 'colorIMG_189.png\\n', 'colorIMG_142.png\\n', 'colorIMG_160.png\\n', 'colorIMG_92.png\\n', 'colorIMG_139.png\\n', 'colorIMG_165.png\\n', 'colorIMG_79.png\\n', 'colorIMG_187.png\\n', 'colorIMG_78.png\\n', 'colorIMG_195.png\\n', 'colorIMG_106.png\\n', 'colorIMG_193.png\\n', 'colorIMG_82.png\\n', 'colorIMG_148.png\\n', 'colorIMG_143.png\\n', 'colorIMG_16.png\\n', 'colorIMG_136.png\\n', 'colorIMG_174.png\\n', 'colorIMG_134.png\\n', 'colorIMG_197.png\\n', 'colorIMG_162.png\\n', 'colorIMG_58.png\\n', 'colorIMG_64.png\\n', 'colorIMG_172.png\\n', 'colorIMG_179.png\\n', 'colorIMG_129.png\\n', 'colorIMG_127.png\\n', 'colorIMG_86.png\\n', 'colorIMG_101.png\\n', 'colorIMG_94.png\\n', 'colorIMG_135.png\\n', 'colorIMG_54.png\\n', 'colorIMG_157.png\\n', 'colorIMG_175.png\\n', 'colorIMG_1.png\\n', 'colorIMG_111.png\\n', 'colorIMG_84.png\\n', 'colorIMG_39.png\\n', 'colorIMG_184.png\\n', 'colorIMG_116.png\\n', 'colorIMG_200.png\\n', 'colorIMG_98.png\\n', 'colorIMG_155.png\\n', 'colorIMG_49.png\\n', 'colorIMG_112.png\\n', 'colorIMG_196.png\\n', 'colorIMG_181.png\\n', 'colorIMG_10.png\\n', 'colorIMG_167.png\\n', 'colorIMG_156.png\\n', 'colorIMG_8.png\\n', 'colorIMG_182.png\\n', 'colorIMG_60.png\\n', 'colorIMG_110.png\\n', 'colorIMG_75.png\\n', 'colorIMG_35.png\\n', 'colorIMG_137.png\\n', 'colorIMG_70.png\\n']\n"
     ]
    }
   ],
   "source": [
    "file_location = '../../Create-CSV-dataset/list_of_img_in_train_set_03-03.csv'\n",
    "place_to_store_results = 'Evaluations/Training/'\n",
    "path_img_folder = '../../../03 Data/Simple Dataset/'\n",
    "\n",
    "# import data\n",
    "file = open(file_location)\n",
    "file_paths = list(file)  \n",
    "\n",
    "print(file_paths)\n",
    "\n",
    "# import model\n",
    "model_path = os.path.join('..', 'snapshots', 'resnet50_csv_25.h5');\n",
    "\n",
    "model = models.load_model(model_path, backbone_name='resnet50');\n",
    "\n",
    "# If model is not converted to inference model, use line below: \n",
    "model = models.convert_model(model)\n",
    "\n",
    "\n",
    "labels_to_names = {0: 'Brick'};\n",
    "\n",
    "#labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations_from_json(img_name):\n",
    "    print(path_img_folder + img_name.strip('.png') + '.json')\n",
    "    with open(path_img_folder + img_name.strip('.png') + '.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        shapes_list = data['shapes']\n",
    "        annotation_list = []\n",
    "        for annotation in shapes_list: \n",
    "            rect = cv2.boundingRect(np.float32(annotation['points']))\n",
    "            annotation_list.append(rect)\n",
    "    return annotation_list; \n",
    "\n",
    "def filter_bounding_boxes(bounding_boxes, scores):\n",
    "    list_of_BB = []\n",
    "    for box, score in zip(bounding_boxes, scores):\n",
    "        if score < 0.7: \n",
    "            break\n",
    "        list_of_BB.append(box)\n",
    "    return list_of_BB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_23.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_102.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_46.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_141.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_188.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_4.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_199.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_123.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_108.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_2.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_30.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_96.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_95.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_85.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_11.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_81.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_28.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_152.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_20.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_59.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_87.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_118.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_91.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_53.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_56.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_9.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_62.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_80.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_69.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_45.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_71.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_104.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_159.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_173.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_154.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_122.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_147.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_38.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_90.json\n",
      "300\n",
      "../../../03 Data/Simple Dataset/colorIMG_74.json\n"
     ]
    }
   ],
   "source": [
    "accept_BB_threshold = 0.7\n",
    "\n",
    "for path in file_paths:\n",
    "    image = read_image_bgr(path_img_folder + path.strip('\\n'))\n",
    "\n",
    "    # create copy to draw on \n",
    "    draw = image.copy()\n",
    "    #draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # preprocess image \n",
    "    # TODOD: check if preprocess_image convert the image to RGB format\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    \n",
    "    # process image \n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    \n",
    "    print(len(boxes[0]))\n",
    "    # print detections\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < accept_BB_threshold:\n",
    "            break\n",
    "\n",
    "        color = label_color(label)\n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "    \n",
    "    # load json file containing annotations\n",
    "    annotations = read_annotations_from_json(path.strip('\\n'))\n",
    "    \n",
    "    \n",
    "    # find overlaping bounding boxes \n",
    "    predictions = filter_bounding_boxes(boxes[0], scores[0])\n",
    "        #calculate intersection and union of two bounding boxes\n",
    "    \n",
    "    # calculate true positives, false negatives, false positives. \n",
    "    \n",
    "    \n",
    "    # store image\n",
    "    cv2.imwrite(place_to_store_results + path.strip('\\n'), draw)\n",
    "\n",
    "# Calculate precision, recall and F1 score \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
