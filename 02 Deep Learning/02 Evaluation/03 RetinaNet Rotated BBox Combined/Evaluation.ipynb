{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File names etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_rep 0: Full unit circle, angle_rep 1: Right half plane, angle_rep 2: Regular angle\n",
    "angle_rep = 0\n",
    "img_list_file = '../list_of_img_in_val_set_18-03.csv'\n",
    "#img_list_file = '../list_of_img_in_OP_val_set_14-04.csv'\n",
    "\n",
    "anchor_config = './config.ini'\n",
    "\n",
    "#path_img_folder = '../../../03 Data/Dataset2_onPallet/' Simple Dataset\n",
    "path_img_folder = '../../../03 Data/Simple Dataset/' \n",
    "\n",
    "\n",
    "model_folder = \"./02 On Pallet Dataset/01 Snapshots/\"\n",
    "model_name = \"OP_Rotated_comb_norm_resnet50_csv_25.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '', '/home/paperspace/HPM/HPMenv/lib/python3.6/site-packages', '/home/paperspace/HPM/HPMenv/lib/python3.6/site-packages/IPython/extensions', '/home/paperspace/.ipython', '/home/paperspace/HPM/BachelorProject/02 Deep Learning']\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(sys.path)\n",
    "# import keras_retinanet\n",
    "#from keras_retinanet import models\n",
    "from RetinaNet_Rotated_Comb.keras_retinanet import models\n",
    "\n",
    "from RetinaNet_Rotated_Comb.keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from RetinaNet_Rotated_Comb.keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from RetinaNet_Rotated_Comb.keras_retinanet.utils.colors import label_color\n",
    "from RetinaNet_Rotated_Comb.keras_retinanet.utils.gpu import setup_gpu\n",
    "from RetinaNet_Rotated_Comb.keras_retinanet.utils.config import parse_anchor_parameters\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "# set the modified tf session as backend in keras  \n",
    "#setup_gpu(gpu)  #NOTICE: enable when using paperspace server!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput a list of RotatedRects as annotations\n",
    "def read_annotations_from_json(img_name):\n",
    "    with open(path_img_folder + img_name.strip('.png') + '.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        shapes_list = data['shapes']\n",
    "        rot_rect_list= []\n",
    "        for annotation in shapes_list: \n",
    "            #rect = cv2.boundingRect(np.float32(annotation['points']))\n",
    "            rot_rect = cv2.minAreaRect(np.float32(annotation['points']))\n",
    "            if rot_rect[-2][0] < rot_rect[-2][1]:\n",
    "                rot_rect = (rot_rect[0],(rot_rect[-2][1],rot_rect[-2][0]),rot_rect[-1]+90)\n",
    "            # make sure that no angle is above 90 or below -90\n",
    "            if rot_rect[-1] > 90:\n",
    "                rot_rect = (rot_rect[0],rot_rect[1],rot_rect[-1]-180)\n",
    "            if rot_rect[-1] < -90:\n",
    "                rot_rect = (rot_rect[0],rot_rect[1],rot_rect[-1]+180)\n",
    "            rot_rect_list.append(rot_rect)\n",
    "    return rot_rect_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_rect_area(rot_rect):\n",
    "    width = rot_rect[1][0]\n",
    "    height = rot_rect[1][1]\n",
    "    return height * width\n",
    "\n",
    "def rot_rect_intersection(rot_rect1, rot_rect2):\n",
    "    check, points = cv2.rotatedRectangleIntersection(rot_rect1,rot_rect2)\n",
    "    if check != 0:\n",
    "        #hull = cv.convexHull(points)\n",
    "        area = cv2.contourArea(points)\n",
    "    else:\n",
    "        area = 0\n",
    "    return area\n",
    "\n",
    "def rot_rect_union(rot_rect1, rot_rect2): \n",
    "    return rot_rect_area(rot_rect1) + rot_rect_area(rot_rect2) - rot_rect_intersection(rot_rect1, rot_rect2)\n",
    "\n",
    "def rot_rect_IoU(rot_rect1, rot_rect2):\n",
    "    return rot_rect_intersection(rot_rect1, rot_rect2)/rot_rect_union(rot_rect1, rot_rect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(bboxes, scores, labels, angles, score_threshold):\n",
    "    filtered_bboxes = []\n",
    "    filtered_scores = []\n",
    "    filtered_labels = []\n",
    "    filtered_angles = []\n",
    "    \n",
    "    for bbox, score, label, angle in zip(bboxes, scores, labels, angles):\n",
    "        if score < score_threshold: \n",
    "            break\n",
    "            \n",
    "        filtered_bboxes.append(bbox)\n",
    "        filtered_scores.append(float(score))\n",
    "        filtered_labels.append(label)\n",
    "        filtered_angles.append(angle)\n",
    "\n",
    "    return filtered_bboxes, filtered_scores, filtered_labels, filtered_angles\n",
    "\n",
    "def format_angles(angles, rep):\n",
    "    formatted_angles = []\n",
    "    if rep == 0:\n",
    "        for angle in angles:\n",
    "            formatted_angles.append(np.arctan2(angle[1],angle[0])/2/np.pi*180)\n",
    "    elif rep == 1:\n",
    "        for angle in angles:\n",
    "            formatted_angles.append(np.arctan2(angle[1],angle[0])/np.pi*180)\n",
    "    elif rep == 2:\n",
    "        formatted_angles.append(angle/np.pi*180)\n",
    "    return formatted_angles \n",
    "\n",
    "def convert_to_rot_rect(bboxes, angles, rep):\n",
    "    rot_rect_list = []\n",
    "    f_angles = format_angles(angles, rep)\n",
    "    for box, angle in zip (bboxes, f_angles):\n",
    "        center_x = (box[0]+box[2])/2\n",
    "        center_y = (box[1]+box[3])/2\n",
    "        w = abs(box[2]-box[0])\n",
    "        h = abs(box[3]-box[1])\n",
    "        rot_rect_list.append(((center_x, center_y),(w, h), angle))\n",
    "    return rot_rect_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a matrix of IoU between prediction and annotation rectangles. The predictions and annotations with the highest IoU\n",
    "# are matched. The matching indices and associated IoU-scores are reported as (pred_idx, anno_idx, IoU)\n",
    "def match_annotations(rot_rect_predictions, rot_rect_annotations):\n",
    "    #create the matrix\n",
    "    IoU_mat = np.zeros((len(rot_rect_predictions), len(rot_rect_annotations)))\n",
    "    # fill matrix with IoU values\n",
    "    for pred_idx, pred in enumerate(rot_rect_predictions):\n",
    "        for anno_idx, anno in enumerate(rot_rect_annotations):\n",
    "            IoU_mat[pred_idx, anno_idx] = rot_rect_IoU(pred, anno)\n",
    "    \n",
    "    # create output list\n",
    "    annotation_matches = []\n",
    "    if IoU_mat.size != 0:\n",
    "        max_idx = np.unravel_index(np.argmax(IoU_mat, axis=None), IoU_mat.shape)\n",
    "        max_IoU = IoU_mat[max_idx]\n",
    "        while max_IoU > 0:\n",
    "            # set the chosen rows and columns to 0\n",
    "            IoU_mat[max_idx[0],:] = 0\n",
    "            IoU_mat[:,max_idx[1]] = 0\n",
    "            # append the indices and IoU to result\n",
    "            annotation_matches.append((max_idx[0],max_idx[1],max_IoU))\n",
    "            max_idx = np.unravel_index(np.argmax(IoU_mat, axis=None), IoU_mat.shape)\n",
    "            max_IoU = IoU_mat[max_idx]\n",
    "    \n",
    "    return annotation_matches\n",
    "\n",
    "# Returns (T. Pos, F. Pos, F. Neg) for certain threshold\n",
    "def evaluate_bb(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    true_pos = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        i+=1\n",
    "        true_pos+=1\n",
    "    false_pos = len(predictions) - true_pos;\n",
    "    false_neg = len(annotations) - true_pos;\n",
    "    return true_pos, false_pos, false_neg\n",
    "\n",
    "# Returns the sum of angle errors and squared sum of angle errors for true positives\n",
    "# Errors are assumed in degrees\n",
    "def evaluate_angle(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    angle_err = 0\n",
    "    angle_err_sqr = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        pred_idx, anno_idx = annotation_matches[i][0:-1]\n",
    "        diff = annotations[anno_idx][-1] - predictions[pred_idx][-1] # using the last element of the tuple, which is the angle\n",
    "        diff = min(abs(diff), abs(diff-180), abs(diff+180)) # makes sure that the sigularity does not skew the results. Assumes degrees\n",
    "        angle_err += diff\n",
    "        angle_err_sqr += diff**2\n",
    "        i+=1\n",
    "    return angle_err, angle_err_sqr\n",
    "\n",
    "def evaluate_center_point(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    center_pt_err = 0\n",
    "    center_pt_err_sqr = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        pred_idx, anno_idx = annotation_matches[i][0:-1]\n",
    "        diff = np.sqrt((annotations[anno_idx][0][0] - predictions[pred_idx][0][0])**2 + (annotations[anno_idx][0][1] - predictions[pred_idx][0][1])**2) \n",
    "        center_pt_err += diff\n",
    "        center_pt_err_sqr += diff**2\n",
    "        i+=1\n",
    "    return center_pt_err, center_pt_err_sqr\n",
    "\n",
    "# finds annotation matches and calls evaluate_bb and evaluate_angle for several IoU-thresholds\n",
    "# ongoing_results is a tuple (total_T_pos, total_F_pos, total_F_neg, angle_err_sum, angle_err_sqr_sum, center_pt_err_sum, center_pt_err_sqr_sum)\n",
    "def evaluate_range(ongoing_results, rot_rect_preds, rot_rect_annos, thresholds):\n",
    "    annotation_matches = match_annotations(rot_rect_preds, rot_rect_annos)\n",
    "    for idx, thresh in enumerate(thresholds):\n",
    "        true_pos, false_pos, false_neg = evaluate_bb(rot_rect_preds, rot_rect_annos, annotation_matches, thresh)\n",
    "        angle_err, angle_err_sqr = evaluate_angle(rot_rect_preds, rot_rect_annos, annotation_matches, thresh)\n",
    "        center_pt_err, center_pt_err_sqr = evaluate_center_point(rot_rect_preds, rot_rect_annos, annotation_matches, thresh)\n",
    "        ongoing_results[idx][0] += true_pos \n",
    "        ongoing_results[idx][1] += false_pos\n",
    "        ongoing_results[idx][2] += false_neg\n",
    "        ongoing_results[idx][3] += angle_err\n",
    "        ongoing_results[idx][4] += angle_err_sqr\n",
    "        ongoing_results[idx][5] += center_pt_err\n",
    "        ongoing_results[idx][6] += center_pt_err_sqr\n",
    "        \n",
    "    return ongoing_results\n",
    "\n",
    "#Returns tuple (thresh, prec, rec, f1, avg_ang_err, std_ang_err, avg_center_err, std_center_err, t_pos, f_pos, f_neg)\n",
    "def get_result(final_results, thresholds):\n",
    "    result = []\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    avg_avg_ang_err = 0\n",
    "    avg_std_ang_err = 0\n",
    "    avg_avg_center_err = 0\n",
    "    avg_std_center_err = 0\n",
    "    for final_res, thresh in zip(final_results, thresholds):\n",
    "        precision = final_res[0]/(final_res[0]+final_res[1])\n",
    "        recall = final_res[0]/(final_res[0]+final_res[2])\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "        avg_ang_err = final_res[3]/final_res[0]\n",
    "        std_ang_err = np.sqrt((final_res[4]/final_res[0])-(avg_ang_err**2))\n",
    "        avg_center_err = final_res[5]/final_res[0]\n",
    "        std_center_err = np.sqrt((final_res[6]/final_res[0])-(avg_center_err**2))\n",
    "        result.append((thresh,precision, recall, f1, avg_ang_err, std_ang_err, avg_center_err, std_center_err, final_res[0], final_res[1], final_res[2]))\n",
    "        avg_prec += precision\n",
    "        avg_rec += recall\n",
    "        avg_avg_ang_err += avg_ang_err\n",
    "        avg_std_ang_err += std_ang_err\n",
    "        avg_avg_center_err += avg_center_err\n",
    "        avg_std_center_err += std_center_err\n",
    "    # append the average at the end \n",
    "    l = len(thresholds)\n",
    "    result.append(('Avg', avg_prec/l, avg_rec/l, 2*avg_prec/l*avg_rec/l/(avg_prec/l+avg_rec/l), avg_avg_ang_err/l, avg_std_ang_err/l,avg_avg_center_err/l, avg_std_center_err/l, '--','--','--'))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(folder, name, results, time):\n",
    "    with open(folder + name, 'w') as f:\n",
    "        f.write('IoU, Prec., Rec., F1, ang. err., std. ang. err., cent. err., std. cent. err. ,F. Neg, F. Pos, T. Pos \\n')\n",
    "        for result in results:\n",
    "            f.write(str(result[0])+', '+str(result[1])+', '+str(result[2])+', '+str(result[3])+', '+str(result[4])+', '+str(result[5])+ ', '+str(result[6])+', '+str(result[7])+', '+str(result[10])+', '+str(result[9])+', '+str(result[8])+'\\n')\n",
    "        f.write('Time: '+str(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predictions(rot_rect_preds, img, save_loc):\n",
    "    for rect in rot_rect_preds:\n",
    "        box = cv2.boxPoints(rect) \n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(img,[box],0,(0,0,255),2)\n",
    "    cv2.imwrite(save_loc, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-32.    ,  -8.    ,  32.    ,   8.    ],\n",
      "       [-40.3168, -10.0792,  40.3168,  10.0792],\n",
      "       [-50.7968, -12.6992,  50.7968,  12.6992]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[ -64.    ,  -16.    ,   64.    ,   16.    ],\n",
      "       [ -80.6336,  -20.1584,   80.6336,   20.1584],\n",
      "       [-101.5936,  -25.3984,  101.5936,   25.3984]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-128.    ,  -32.    ,  128.    ,   32.    ],\n",
      "       [-161.2672,  -40.3168,  161.2672,   40.3168],\n",
      "       [-203.1872,  -50.7968,  203.1872,   50.7968]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-256.    ,  -64.    ,  256.    ,   64.    ],\n",
      "       [-322.5344,  -80.6336,  322.5344,   80.6336],\n",
      "       [-406.3744, -101.5936,  406.3744,  101.5936]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-512.    , -128.    ,  512.    ,  128.    ],\n",
      "       [-645.0688, -161.2672,  645.0688,  161.2672],\n",
      "       [-812.7488, -203.1872,  812.7488,  203.1872]], dtype=float32)> anchors\n",
      "regression Tensor(\"split/stack:0\", shape=(None, None, 4), dtype=float32)\n",
      "other Tensor(\"split/stack_1:0\", shape=(None, None, 2), dtype=float32)\n",
      "boxes Tensor(\"clipped_boxes/stack:0\", shape=(None, None, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "model_path = os.path.join(model_folder, model_name);\n",
    "model = models.load_model(model_path, backbone_name='resnet50');\n",
    "\n",
    "# If model is not converted to inference model, use line below: \n",
    "#anchor_params = parse_anchor_parameters(anchor_config)\n",
    "model = models.convert_model(model, nms=False);\n",
    "\n",
    "# Mapping of model output and classes\n",
    "labels_to_names = {0: 'Brick'};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "8\n",
      "16\n",
      "11\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "15\n",
      "14\n",
      "13\n",
      "14\n",
      "14\n",
      "7\n",
      "16\n",
      "16\n",
      "14\n",
      "15\n",
      "16\n",
      "16\n",
      "15\n",
      "14\n",
      "16\n",
      "12\n",
      "16\n",
      "16\n",
      "15\n",
      "15\n",
      "14\n",
      "16\n",
      "16\n",
      "16\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "file = open(img_list_file)\n",
    "file_paths = list(file)\n",
    "#file_paths = file_paths[0:30]\n",
    "\n",
    "IoU_thresholds = np.arange(0.5,1,0.05)\n",
    "\n",
    "ongoing_results = np.zeros((len(IoU_thresholds),7))\n",
    "\n",
    "total_time = 0\n",
    "for path in file_paths:\n",
    "    image = read_image_bgr(path_img_folder + path.strip('\\n'))\n",
    "    draw = image.copy()\n",
    "    #draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    start = time.perf_counter()\n",
    "    # preprocess image \n",
    "    # TODOD: check if preprocess_image convert the image to RGB format\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    # process image \n",
    "    boxes, scores, labels, angles = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    # correct for image scale  \n",
    "    boxes /= scale\n",
    "    boxes, scores, labels, angles = filter_predictions(boxes[0], scores[0], labels[0], angles[0], 0.9)\n",
    "    \n",
    "    rot_rect_preds = convert_to_rot_rect(boxes, angles, angle_rep)\n",
    "    #do some nms\n",
    "    \n",
    "    indices=cv2.dnn.NMSBoxesRotated(rot_rect_preds, scores, 0.2, 0.15)\n",
    "    indices = list(map(int,indices))\n",
    "        \n",
    "    print(len(indices))\n",
    "    rot_rect_preds = [rot_rect_preds[x] for x in indices]\n",
    "    scores = [scores[x] for x in indices]\n",
    "    labels = [labels[x] for x in indices]\n",
    "    end = time.perf_counter()\n",
    "    total_time += end-start\n",
    "    \n",
    "    ##load annotations\n",
    "    rot_rect_annos = read_annotations_from_json(path.strip('\\n')) \n",
    "    \n",
    "    img = draw_predictions(rot_rect_preds, draw, './02 On Pallet Dataset/02 Evaluation Images/'+path.strip('\\n'))\n",
    "    \n",
    "    ongoing_results =  evaluate_range(ongoing_results, rot_rect_preds, rot_rect_annos, IoU_thresholds) # <- Edit to use RotatedRect\n",
    "final_results = get_result(ongoing_results, IoU_thresholds)\n",
    "write_results('./02 On Pallet Dataset/', model_name[0:-3]+'results_simple.csv', final_results, total_time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.8935869 , -0.43153107], dtype=float32), array([-1.0186518 , -0.37874824], dtype=float32), array([-0.89156634, -0.39893797], dtype=float32), array([-0.8804049, -0.401723 ], dtype=float32), array([-0.8783738 , -0.44939083], dtype=float32), array([-0.943411  , -0.35680312], dtype=float32), array([-0.9660763 , -0.33796355], dtype=float32), array([-0.8934555 , -0.42526776], dtype=float32), array([-0.9551879 , -0.40151384], dtype=float32), array([-1.0217218 , -0.39939684], dtype=float32), array([-0.8969149, -0.5202827], dtype=float32), array([-0.9333686 , -0.37796167], dtype=float32), array([-0.9070306, -0.4518152], dtype=float32), array([-0.9036355 , -0.40104666], dtype=float32), array([-0.8420044 , -0.36035138], dtype=float32), array([-0.89452016, -0.45649177], dtype=float32), array([-0.89242154, -0.47438556], dtype=float32), array([-0.88440984, -0.4029983 ], dtype=float32), array([-0.8905921 , -0.43858784], dtype=float32), array([-0.92299205, -0.5381268 ], dtype=float32), array([-0.8192157 , -0.42518213], dtype=float32), array([-0.92717195, -0.52748686], dtype=float32), array([-0.89359415, -0.46942917], dtype=float32), array([-0.8905267 , -0.47781497], dtype=float32), array([-0.9116953 , -0.40763122], dtype=float32), array([-0.91230667, -0.4180275 ], dtype=float32), array([-0.9123638 , -0.39339653], dtype=float32), array([-0.9091032, -0.4272011], dtype=float32), array([-0.87298715, -0.45187747], dtype=float32), array([-0.9156002, -0.5478338], dtype=float32), array([-0.9422316 , -0.36422637], dtype=float32), array([-0.8968622, -0.3917514], dtype=float32), array([-0.92046124, -0.45522672], dtype=float32), array([-0.9334289 , -0.49165824], dtype=float32), array([-0.90930396, -0.4435192 ], dtype=float32), array([-0.9466047 , -0.37613443], dtype=float32), array([-0.8290117 , -0.51178813], dtype=float32), array([-1.0031812 , -0.32867357], dtype=float32), array([-0.935744  , -0.49276292], dtype=float32), array([-1.0300407 , -0.44405589], dtype=float32), array([-1.0106455, -0.3305125], dtype=float32), array([-0.8705138, -0.4464011], dtype=float32), array([-0.90669614, -0.54115325], dtype=float32), array([-0.9423166 , -0.34559935], dtype=float32), array([-0.8767141 , -0.47918487], dtype=float32), array([-0.9285448 , -0.49686095], dtype=float32), array([-0.93072003, -0.44504875], dtype=float32), array([-0.87462336, -0.5165663 ], dtype=float32), array([-0.94916105, -0.44348273], dtype=float32), array([-0.88570744, -0.44834176], dtype=float32), array([-0.91622967, -0.3656233 ], dtype=float32), array([-0.9077257 , -0.44786245], dtype=float32), array([-0.88581234, -0.3921108 ], dtype=float32), array([-0.9333733, -0.4389521], dtype=float32), array([-0.89391   , -0.42057708], dtype=float32), array([-0.88502336, -0.50471103], dtype=float32), array([-0.89773756, -0.44194096], dtype=float32), array([-0.93218917, -0.3965625 ], dtype=float32), array([-0.9382124 , -0.42827922], dtype=float32), array([-0.9238374, -0.4556384], dtype=float32), array([-0.94805676, -0.45556834], dtype=float32), array([-0.91540444, -0.51235384], dtype=float32), array([-0.8965682, -0.4776773], dtype=float32), array([-0.90699583, -0.4317813 ], dtype=float32), array([-0.8815794 , -0.47318354], dtype=float32), array([-0.90249836, -0.45851156], dtype=float32), array([-0.90362376, -0.42610118], dtype=float32), array([-0.9063527 , -0.45544827], dtype=float32), array([-0.9290109, -0.4595516], dtype=float32), array([-0.9199857, -0.5317917], dtype=float32), array([-0.93580294, -0.5139067 ], dtype=float32), array([-0.93208146, -0.42695323], dtype=float32), array([-0.8857855, -0.4589524], dtype=float32), array([-0.9400131, -0.3194452], dtype=float32), array([-0.9255596 , -0.53484464], dtype=float32), array([-0.9813208, -0.3707224], dtype=float32), array([-0.8900055 , -0.43839788], dtype=float32), array([-0.9151408 , -0.38602126], dtype=float32), array([-0.8869331 , -0.40800238], dtype=float32), array([-0.9885358 , -0.40016356], dtype=float32), array([-0.9162645, -0.4144468], dtype=float32), array([-0.94922245, -0.4330747 ], dtype=float32), array([-0.8751097 , -0.42696527], dtype=float32), array([-0.913192 , -0.4822302], dtype=float32), array([-0.9519338 , -0.38990277], dtype=float32), array([-0.84709126, -0.4686047 ], dtype=float32), array([-0.8757437 , -0.48372284], dtype=float32), array([-0.8992209 , -0.39108095], dtype=float32), array([-0.89451456, -0.39098862], dtype=float32), array([-0.93393886, -0.37271672], dtype=float32), array([-0.90525115, -0.44060454], dtype=float32), array([-0.9924954, -0.3956019], dtype=float32), array([-0.9514457 , -0.37379497], dtype=float32), array([-0.88539904, -0.4750359 ], dtype=float32), array([-0.91742426, -0.3991989 ], dtype=float32), array([-0.8956583 , -0.46233812], dtype=float32), array([-0.8804012 , -0.44787893], dtype=float32), array([-0.9335404 , -0.46275637], dtype=float32), array([-0.9208917 , -0.42549393], dtype=float32), array([-0.9599307 , -0.43908575], dtype=float32), array([-0.9669702 , -0.37043765], dtype=float32), array([-0.90511817, -0.42983803], dtype=float32), array([-0.8866096 , -0.43445843], dtype=float32), array([-0.91637653, -0.47717288], dtype=float32), array([-0.8544199, -0.4306429], dtype=float32), array([-0.8750312, -0.3988613], dtype=float32), array([-0.9124954, -0.379716 ], dtype=float32), array([-0.9466201 , -0.30390224], dtype=float32), array([-0.9155257, -0.4073988], dtype=float32), array([-0.92801267, -0.40893805], dtype=float32), array([-0.90573335, -0.49100974], dtype=float32), array([-0.86519516, -0.43732595], dtype=float32), array([-0.90961576, -0.44382855], dtype=float32), array([-1.0382777, -0.3371266], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
