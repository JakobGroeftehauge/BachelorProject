{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File names etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_rep 0: Full unit circle, angle_rep 1: Right half plane, angle_rep 2: Regular angle\n",
    "angle_rep = 0\n",
    "#img_list_file = '../list_of_img_in_val_set_18-03.csv'\n",
    "img_list_file = '../list_of_img_in_OP_val_set_14-04.csv'\n",
    "\n",
    "anchor_config = './config.ini'\n",
    "\n",
    "path_img_folder = '../../../03 Data/Dataset2_onPallet/'\n",
    "\n",
    "model_folder = \"./02 On Pallet Dataset/01 Snapshots/\"\n",
    "model_name = \"OP_Rotated_Rect_Anchor_025_05_075_resnet50_csv_25.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '', '/home/paperspace/HPM/HPMenv/lib/python3.6/site-packages', '/home/paperspace/HPM/HPMenv/lib/python3.6/site-packages/IPython/extensions', '/home/paperspace/.ipython', '/home/paperspace/HPM/BachelorProject/02 Deep Learning']\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(sys.path)\n",
    "# import keras_retinanet\n",
    "#from keras_retinanet import models\n",
    "from RetinaNet_Rotated_BBox.keras_retinanet import models\n",
    "\n",
    "from RetinaNet_Rotated_BBox.keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from RetinaNet_Rotated_BBox.keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from RetinaNet_Rotated_BBox.keras_retinanet.utils.colors import label_color\n",
    "from RetinaNet_Rotated_BBox.keras_retinanet.utils.gpu import setup_gpu\n",
    "from RetinaNet_Rotated_BBox.keras_retinanet.utils.config import parse_anchor_parameters\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "# set the modified tf session as backend in keras  \n",
    "#setup_gpu(gpu)  #NOTICE: enable when using paperspace server!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput a list of RotatedRects as annotations\n",
    "def read_annotations_from_json(img_name):\n",
    "    with open(path_img_folder + img_name.strip('.png') + '.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        shapes_list = data['shapes']\n",
    "        rot_rect_list= []\n",
    "        for annotation in shapes_list: \n",
    "            #rect = cv2.boundingRect(np.float32(annotation['points']))\n",
    "            rot_rect = cv2.minAreaRect(np.float32(annotation['points']))\n",
    "            if rot_rect[-2][0] < rot_rect[-2][1]:\n",
    "                rot_rect = (rot_rect[0],(rot_rect[-2][1],rot_rect[-2][0]),rot_rect[-1]+90)\n",
    "            # make sure that no angle is above 90 or below -90\n",
    "            if rot_rect[-1] > 90:\n",
    "                rot_rect = (rot_rect[0],rot_rect[1],rot_rect[-1]-180)\n",
    "            if rot_rect[-1] < -90:\n",
    "                rot_rect = (rot_rect[0],rot_rect[1],rot_rect[-1]+180)\n",
    "            rot_rect_list.append(rot_rect)\n",
    "    return rot_rect_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_rect_area(rot_rect):\n",
    "    width = rot_rect[1][0]\n",
    "    height = rot_rect[1][1]\n",
    "    return height * width\n",
    "\n",
    "def rot_rect_intersection(rot_rect1, rot_rect2):\n",
    "    check, points = cv2.rotatedRectangleIntersection(rot_rect1,rot_rect2)\n",
    "    if check != 0:\n",
    "        #hull = cv.convexHull(points)\n",
    "        area = cv2.contourArea(points)\n",
    "    else:\n",
    "        area = 0\n",
    "    return area\n",
    "\n",
    "def rot_rect_union(rot_rect1, rot_rect2): \n",
    "    return rot_rect_area(rot_rect1) + rot_rect_area(rot_rect2) - rot_rect_intersection(rot_rect1, rot_rect2)\n",
    "\n",
    "def rot_rect_IoU(rot_rect1, rot_rect2):\n",
    "    return rot_rect_intersection(rot_rect1, rot_rect2)/rot_rect_union(rot_rect1, rot_rect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(bboxes, scores, labels, angles, score_threshold):\n",
    "    filtered_bboxes = []\n",
    "    filtered_scores = []\n",
    "    filtered_labels = []\n",
    "    filtered_angles = []\n",
    "    \n",
    "    for bbox, score, label, angle in zip(bboxes, scores, labels, angles):\n",
    "        if score < score_threshold: \n",
    "            break\n",
    "            \n",
    "        filtered_bboxes.append(bbox)\n",
    "        filtered_scores.append(float(score))\n",
    "        filtered_labels.append(label)\n",
    "        filtered_angles.append(angle)\n",
    "\n",
    "    return filtered_bboxes, filtered_scores, filtered_labels, filtered_angles\n",
    "\n",
    "def format_angles(angles, rep):\n",
    "    formatted_angles = []\n",
    "    if rep == 0:\n",
    "        for angle in angles:\n",
    "            formatted_angles.append(np.arctan2(angle[1],angle[0])/2/np.pi*180)\n",
    "    elif rep == 1:\n",
    "        for angle in angles:\n",
    "            formatted_angles.append(np.arctan2(angle[1],angle[0])/np.pi*180)\n",
    "    elif rep == 2:\n",
    "        formatted_angles.append(angle/np.pi*180)\n",
    "    return formatted_angles \n",
    "\n",
    "def convert_to_rot_rect(bboxes, angles, rep):\n",
    "    rot_rect_list = []\n",
    "    f_angles = format_angles(angles, rep)\n",
    "    for box, angle in zip (bboxes, f_angles):\n",
    "        center_x = (box[0]+box[2])/2\n",
    "        center_y = (box[1]+box[3])/2\n",
    "        w = abs(box[2]-box[0])\n",
    "        h = abs(box[3]-box[1])\n",
    "        rot_rect_list.append(((center_x, center_y),(w, h), angle))\n",
    "    return rot_rect_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a matrix of IoU between prediction and annotation rectangles. The predictions and annotations with the highest IoU\n",
    "# are matched. The matching indices and associated IoU-scores are reported as (pred_idx, anno_idx, IoU)\n",
    "def match_annotations(rot_rect_predictions, rot_rect_annotations):\n",
    "    #create the matrix\n",
    "    IoU_mat = np.zeros((len(rot_rect_predictions), len(rot_rect_annotations)))\n",
    "    # fill matrix with IoU values\n",
    "    for pred_idx, pred in enumerate(rot_rect_predictions):\n",
    "        for anno_idx, anno in enumerate(rot_rect_annotations):\n",
    "            IoU_mat[pred_idx, anno_idx] = rot_rect_IoU(pred, anno)\n",
    "    \n",
    "    # create output list\n",
    "    annotation_matches = []\n",
    "    if IoU_mat.size != 0:\n",
    "        max_idx = np.unravel_index(np.argmax(IoU_mat, axis=None), IoU_mat.shape)\n",
    "        max_IoU = IoU_mat[max_idx]\n",
    "        while max_IoU > 0:\n",
    "            # set the chosen rows and columns to 0\n",
    "            IoU_mat[max_idx[0],:] = 0\n",
    "            IoU_mat[:,max_idx[1]] = 0\n",
    "            # append the indices and IoU to result\n",
    "            annotation_matches.append((max_idx[0],max_idx[1],max_IoU))\n",
    "            max_idx = np.unravel_index(np.argmax(IoU_mat, axis=None), IoU_mat.shape)\n",
    "            max_IoU = IoU_mat[max_idx]\n",
    "    \n",
    "    return annotation_matches\n",
    "\n",
    "# Returns (T. Pos, F. Pos, F. Neg) for certain threshold\n",
    "def evaluate_bb(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    true_pos = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        i+=1\n",
    "        true_pos+=1\n",
    "    false_pos = len(predictions) - true_pos;\n",
    "    false_neg = len(annotations) - true_pos;\n",
    "    return true_pos, false_pos, false_neg\n",
    "\n",
    "# Returns the sum of angle errors and squared sum of angle errors for true positives\n",
    "# Errors are assumed in degrees\n",
    "def evaluate_angle(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    angle_err = 0\n",
    "    angle_err_sqr = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        pred_idx, anno_idx = annotation_matches[i][0:-1]\n",
    "        diff = annotations[anno_idx][-1] - predictions[pred_idx][-1] # using the last element of the tuple, which is the angle\n",
    "        diff = min(abs(diff), abs(diff-180), abs(diff+180)) # makes sure that the sigularity does not skew the results. Assumes degrees\n",
    "        angle_err += diff\n",
    "        angle_err_sqr += diff**2\n",
    "        i+=1\n",
    "    return angle_err, angle_err_sqr\n",
    "\n",
    "def evaluate_center_point(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    center_pt_err = 0\n",
    "    center_pt_err_sqr = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        pred_idx, anno_idx = annotation_matches[i][0:-1]\n",
    "        diff = np.sqrt((annotations[anno_idx][0][0] - predictions[pred_idx][0][0])**2 + (annotations[anno_idx][0][1] - predictions[pred_idx][0][1])**2) \n",
    "        center_pt_err += diff\n",
    "        center_pt_err_sqr += diff**2\n",
    "        i+=1\n",
    "    return center_pt_err, center_pt_err_sqr\n",
    "\n",
    "# finds annotation matches and calls evaluate_bb and evaluate_angle for several IoU-thresholds\n",
    "# ongoing_results is a tuple (total_T_pos, total_F_pos, total_F_neg, angle_err_sum, angle_err_sqr_sum, center_pt_err_sum, center_pt_err_sqr_sum)\n",
    "def evaluate_range(ongoing_results, rot_rect_preds, rot_rect_annos, thresholds):\n",
    "    annotation_matches = match_annotations(rot_rect_preds, rot_rect_annos)\n",
    "    for idx, thresh in enumerate(thresholds):\n",
    "        true_pos, false_pos, false_neg = evaluate_bb(rot_rect_preds, rot_rect_annos, annotation_matches, thresh)\n",
    "        angle_err, angle_err_sqr = evaluate_angle(rot_rect_preds, rot_rect_annos, annotation_matches, thresh)\n",
    "        center_pt_err, center_pt_err_sqr = evaluate_center_point(rot_rect_preds, rot_rect_annos, annotation_matches, thresh)\n",
    "        ongoing_results[idx][0] += true_pos \n",
    "        ongoing_results[idx][1] += false_pos\n",
    "        ongoing_results[idx][2] += false_neg\n",
    "        ongoing_results[idx][3] += angle_err\n",
    "        ongoing_results[idx][4] += angle_err_sqr\n",
    "        ongoing_results[idx][5] += center_pt_err\n",
    "        ongoing_results[idx][6] += center_pt_err_sqr\n",
    "        \n",
    "    return ongoing_results\n",
    "\n",
    "#Returns tuple (thresh, prec, rec, f1, avg_ang_err, std_ang_err, avg_center_err, std_center_err, t_pos, f_pos, f_neg)\n",
    "def get_result(final_results, thresholds):\n",
    "    result = []\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    avg_avg_ang_err = 0\n",
    "    avg_std_ang_err = 0\n",
    "    avg_avg_center_err = 0\n",
    "    avg_std_center_err = 0\n",
    "    for final_res, thresh in zip(final_results, thresholds):\n",
    "        precision = final_res[0]/(final_res[0]+final_res[1])\n",
    "        recall = final_res[0]/(final_res[0]+final_res[2])\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "        avg_ang_err = final_res[3]/final_res[0]\n",
    "        std_ang_err = np.sqrt((final_res[4]/final_res[0])-(avg_ang_err**2))\n",
    "        avg_center_err = final_res[5]/final_res[0]\n",
    "        std_center_err = np.sqrt((final_res[6]/final_res[0])-(avg_center_err**2))\n",
    "        result.append((thresh,precision, recall, f1, avg_ang_err, std_ang_err, avg_center_err, std_center_err, final_res[0], final_res[1], final_res[2]))\n",
    "        avg_prec += precision\n",
    "        avg_rec += recall\n",
    "        avg_avg_ang_err += avg_ang_err\n",
    "        avg_std_ang_err += std_ang_err\n",
    "        avg_avg_center_err += avg_center_err\n",
    "        avg_std_center_err += std_center_err\n",
    "    # append the average at the end \n",
    "    l = len(thresholds)\n",
    "    result.append(('Avg', avg_prec/l, avg_rec/l, 2*avg_prec/l*avg_rec/l/(avg_prec/l+avg_rec/l), avg_avg_ang_err/l, avg_std_ang_err/l,avg_avg_center_err/l, avg_std_center_err/l, '--','--','--'))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(folder, name, results, time):\n",
    "    with open(folder + name, 'w') as f:\n",
    "        f.write('IoU, Prec., Rec., F1, ang. err., std. ang. err., cent. err., std. cent. err. ,F. Neg, F. Pos, T. Pos \\n')\n",
    "        for result in results:\n",
    "            f.write(str(result[0])+', '+str(result[1])+', '+str(result[2])+', '+str(result[3])+', '+str(result[4])+', '+str(result[5])+ ', '+str(result[6])+', '+str(result[7])+', '+str(result[10])+', '+str(result[9])+', '+str(result[8])+'\\n')\n",
    "        f.write('Time: '+str(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predictions(rot_rect_preds, img, save_loc):\n",
    "    for rect in rot_rect_preds:\n",
    "        box = cv2.boxPoints(rect) \n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(img,[box],0,(0,0,255),2)\n",
    "    cv2.imwrite(save_loc, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-32.      ,  -8.      ,  32.      ,   8.      ],\n",
      "       [-40.3168  , -10.0792  ,  40.3168  ,  10.0792  ],\n",
      "       [-50.7968  , -12.6992  ,  50.7968  ,  12.6992  ],\n",
      "       [-22.627417, -11.313708,  22.627417,  11.313708],\n",
      "       [-28.508282, -14.254141,  28.508282,  14.254141],\n",
      "       [-35.918762, -17.959381,  35.918762,  17.959381],\n",
      "       [-18.475208, -13.856406,  18.475208,  13.856406],\n",
      "       [-23.276915, -17.457685,  23.276915,  17.457685],\n",
      "       [-29.327545, -21.995659,  29.327545,  21.995659]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[ -64.      ,  -16.      ,   64.      ,   16.      ],\n",
      "       [ -80.6336  ,  -20.1584  ,   80.6336  ,   20.1584  ],\n",
      "       [-101.5936  ,  -25.3984  ,  101.5936  ,   25.3984  ],\n",
      "       [ -45.254833,  -22.627417,   45.254833,   22.627417],\n",
      "       [ -57.016563,  -28.508282,   57.016563,   28.508282],\n",
      "       [ -71.837524,  -35.918762,   71.837524,   35.918762],\n",
      "       [ -36.950417,  -27.712812,   36.950417,   27.712812],\n",
      "       [ -46.55383 ,  -34.91537 ,   46.55383 ,   34.91537 ],\n",
      "       [ -58.65509 ,  -43.991318,   58.65509 ,   43.991318]],\n",
      "      dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-128.      ,  -32.      ,  128.      ,   32.      ],\n",
      "       [-161.2672  ,  -40.3168  ,  161.2672  ,   40.3168  ],\n",
      "       [-203.1872  ,  -50.7968  ,  203.1872  ,   50.7968  ],\n",
      "       [ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
      "       [-114.03313 ,  -57.016563,  114.03313 ,   57.016563],\n",
      "       [-143.67505 ,  -71.837524,  143.67505 ,   71.837524],\n",
      "       [ -73.90083 ,  -55.425625,   73.90083 ,   55.425625],\n",
      "       [ -93.10766 ,  -69.83074 ,   93.10766 ,   69.83074 ],\n",
      "       [-117.31018 ,  -87.982635,  117.31018 ,   87.982635]],\n",
      "      dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-256.     ,  -64.     ,  256.     ,   64.     ],\n",
      "       [-322.5344 ,  -80.6336 ,  322.5344 ,   80.6336 ],\n",
      "       [-406.3744 , -101.5936 ,  406.3744 ,  101.5936 ],\n",
      "       [-181.01933,  -90.50967,  181.01933,   90.50967],\n",
      "       [-228.06625, -114.03313,  228.06625,  114.03313],\n",
      "       [-287.3501 , -143.67505,  287.3501 ,  143.67505],\n",
      "       [-147.80167, -110.85125,  147.80167,  110.85125],\n",
      "       [-186.21532, -139.66148,  186.21532,  139.66148],\n",
      "       [-234.62036, -175.96527,  234.62036,  175.96527]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-512.     , -128.     ,  512.     ,  128.     ],\n",
      "       [-645.0688 , -161.2672 ,  645.0688 ,  161.2672 ],\n",
      "       [-812.7488 , -203.1872 ,  812.7488 ,  203.1872 ],\n",
      "       [-362.03867, -181.01933,  362.03867,  181.01933],\n",
      "       [-456.1325 , -228.06625,  456.1325 ,  228.06625],\n",
      "       [-574.7002 , -287.3501 ,  574.7002 ,  287.3501 ],\n",
      "       [-295.60333, -221.7025 ,  295.60333,  221.7025 ],\n",
      "       [-372.43063, -279.32297,  372.43063,  279.32297],\n",
      "       [-469.24072, -351.93054,  469.24072,  351.93054]], dtype=float32)> anchors\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "model_path = os.path.join(model_folder, model_name);\n",
    "model = models.load_model(model_path, backbone_name='resnet50');\n",
    "\n",
    "# If model is not converted to inference model, use line below: \n",
    "#anchor_params = parse_anchor_parameters(anchor_config)\n",
    "model = models.convert_model(model, nms=False);\n",
    "\n",
    "# Mapping of model output and classes\n",
    "labels_to_names = {0: 'Brick'};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "16\n",
      "16\n",
      "1\n",
      "15\n",
      "8\n",
      "1\n",
      "10\n",
      "15\n",
      "9\n",
      "15\n",
      "14\n",
      "16\n",
      "12\n",
      "15\n",
      "2\n",
      "13\n",
      "10\n",
      "13\n",
      "14\n",
      "11\n",
      "10\n",
      "13\n",
      "16\n",
      "16\n",
      "13\n",
      "14\n",
      "10\n",
      "9\n",
      "14\n",
      "12\n",
      "13\n",
      "12\n",
      "9\n",
      "13\n",
      "15\n",
      "13\n",
      "14\n",
      "15\n",
      "8\n",
      "16\n",
      "13\n",
      "11\n",
      "14\n",
      "11\n",
      "13\n",
      "10\n",
      "14\n",
      "10\n",
      "15\n",
      "10\n",
      "15\n",
      "8\n",
      "2\n",
      "10\n",
      "12\n",
      "14\n",
      "6\n",
      "13\n",
      "16\n",
      "11\n",
      "16\n",
      "1\n",
      "15\n",
      "13\n",
      "14\n",
      "8\n",
      "12\n",
      "15\n",
      "16\n",
      "11\n",
      "13\n",
      "11\n",
      "9\n",
      "9\n",
      "15\n",
      "3\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "12\n",
      "3\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "13\n",
      "8\n",
      "11\n",
      "10\n",
      "10\n",
      "15\n",
      "11\n",
      "16\n",
      "16\n",
      "8\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "file = open(img_list_file)\n",
    "file_paths = list(file)\n",
    "#file_paths = file_paths[0:30]\n",
    "\n",
    "IoU_thresholds = np.arange(0.5,1,0.05)\n",
    "\n",
    "ongoing_results = np.zeros((len(IoU_thresholds),7))\n",
    "\n",
    "total_time = 0\n",
    "for path in file_paths:\n",
    "    image = read_image_bgr(path_img_folder + path.strip('\\n'))\n",
    "    draw = image.copy()\n",
    "    #draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    start = time.perf_counter()\n",
    "    # preprocess image \n",
    "    # TODOD: check if preprocess_image convert the image to RGB format\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    # process image \n",
    "    boxes, scores, labels, angles = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    boxes, scores, labels, angles = filter_predictions(boxes[0], scores[0], labels[0], angles[0], 0.9)\n",
    "    \n",
    "    rot_rect_preds = convert_to_rot_rect(boxes, angles, angle_rep)\n",
    "    #do some nms\n",
    "    \n",
    "    indices=cv2.dnn.NMSBoxesRotated(rot_rect_preds, scores, 0.2, 0.15)\n",
    "    indices = list(map(int,indices))\n",
    "        \n",
    "    print(len(indices))\n",
    "    rot_rect_preds = [rot_rect_preds[x] for x in indices]\n",
    "    scores = [scores[x] for x in indices]\n",
    "    labels = [labels[x] for x in indices]\n",
    "    end = time.perf_counter()\n",
    "    total_time += end-start\n",
    "    \n",
    "    ##load annotations\n",
    "    rot_rect_annos = read_annotations_from_json(path.strip('\\n')) \n",
    "    \n",
    "    img = draw_predictions(rot_rect_preds, draw, './02 On Pallet Dataset/02 Evaluation Images/'+path.strip('\\n'))\n",
    "    \n",
    "    ongoing_results =  evaluate_range(ongoing_results, rot_rect_preds, rot_rect_annos, IoU_thresholds) # <- Edit to use RotatedRect\n",
    "final_results = get_result(ongoing_results, IoU_thresholds)\n",
    "write_results('./02 On Pallet Dataset/', model_name[0:-3]+'results_center.csv', final_results, total_time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
