{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File names etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_rep 0: Full unit circle, angle_rep 1: Right half plane, angle_rep 2: Regular angle\n",
    "angle_rep = 0\n",
    "#img_list_file = 'list_of_img_in_val_set_18-03.csv'\n",
    "img_list_file = '../list_of_img_in_OP_val_set_14-04.csv'\n",
    "\n",
    "path_img_folder = '../../../03 Data/Dataset2_onPallet/'\n",
    "\n",
    "model_folder = \"./02 On Pallet Dataset/01 Snapshots/\"\n",
    "model_name = \"OP_Full_SmoothL1_05_resnet50_csv_25.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "# set the modified tf session as backend in keras  \n",
    "#setup_gpu(gpu)  #NOTICE: enable when using paperspace server!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bp_to_aabb(points):\n",
    "    max_x = max(points[:,0])\n",
    "    min_x = min(points[:,0])\n",
    "    max_y = max(points[:,1])\n",
    "    min_y = min(points[:,1])\n",
    "\n",
    "    return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "def read_annotations_from_json(img_name):\n",
    "    with open(path_img_folder + img_name.strip('.png') + '.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        shapes_list = data['shapes']\n",
    "        bbox_list = []\n",
    "        angle_list = []\n",
    "        for annotation in shapes_list: \n",
    "            #rect = cv2.boundingRect(np.float32(annotation['points']))\n",
    "            rot_rect = cv2.minAreaRect(np.float32(annotation['points']))\n",
    "            if rot_rect[-2][0] < rot_rect[-2][1]:\n",
    "                rot_rect = (rot_rect[0],(rot_rect[-2][1],rot_rect[-2][0]),rot_rect[-1]+90)\n",
    "            # make sure that no angle is above 90 or below -90\n",
    "            if rot_rect[-1] > 90:\n",
    "                rot_rect = (rot_rect[0],rot_rect[1],rot_rect[-1]-180)\n",
    "            if rot_rect[-1] < -90:\n",
    "                rot_rect = (rot_rect[0],rot_rect[1],rot_rect[-1]+180)\n",
    "            #angle_list.append(rot_rect[-1]/180*np.pi)\n",
    "            bp = cv2.boxPoints(rot_rect)\n",
    "            angle_list.append(rot_rect[-1])\n",
    "            bbox_list.append(convert_bp_to_aabb(bp))\n",
    "    return bbox_list, angle_list; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(BB):\n",
    "    width = abs(BB[0] - BB[2])\n",
    "    height = abs(BB[1] - BB[3])\n",
    "    return height * width\n",
    "\n",
    "def intersection(BB1, BB2):\n",
    "    # find coordiantes of intersection rectangle \n",
    "    (x1, y1, x2, y2) = BB1\n",
    "    (x3, y3, x4, y4) = BB2\n",
    "    if x1 > x4 or x3 > x2 or y3 > y2 or y1 > y4:\n",
    "        return 0\n",
    "    x5 = max(x1, x3);\n",
    "    y5 = max(y1, y3);\n",
    "    x6 = min(x2, x4);\n",
    "    y6 = min(y2, y4);  \n",
    "    BB = (x5, y5, x6, y6)\n",
    "    # TODO: check if no intersection exists\n",
    "    return area(BB)\n",
    "\n",
    "def union(BB1, BB2): \n",
    "    return area(BB1) + area(BB2) - intersection(BB1, BB2)\n",
    "\n",
    "def IoU(BB1, BB2):\n",
    "    return intersection(BB1, BB2)/union(BB1, BB2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(bboxes, scores, labels, angles, score_threshold):\n",
    "    filtered_bboxes = []\n",
    "    filtered_scores = []\n",
    "    filtered_labels = []\n",
    "    filtered_angles = []\n",
    "    \n",
    "    for bbox, score, label, angle in zip(bboxes, scores, labels, angles):\n",
    "        if score < score_threshold: \n",
    "            break\n",
    "            \n",
    "        filtered_bboxes.append(bbox)\n",
    "        filtered_scores.append(score)\n",
    "        filtered_labels.append(label)\n",
    "        filtered_angles.append(angle)\n",
    "\n",
    "    return filtered_bboxes, filtered_scores, filtered_labels, filtered_angles\n",
    "\n",
    "def format_angles(angles, rep):\n",
    "    formatted_angles = []\n",
    "    if rep == 0:\n",
    "        for angle in angles:\n",
    "            formatted_angles.append(np.arctan2(angle[1],angle[0])/2/np.pi*180)\n",
    "    elif rep == 1:\n",
    "        for angle in angles:\n",
    "            formatted_angles.append(np.arctan2(angle[1],angle[0])/np.pi*180)\n",
    "    elif rep == 2:\n",
    "        formatted_angles.append(angle/np.pi*180)\n",
    "    return formatted_angles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a matrix of IoU between prediction and annotation rectangles. The predictions and annotations with the highest IoU\n",
    "# are matched. The matching indices and associated IoU-scores are reported as (pred_idx, anno_idx, IoU)\n",
    "def match_annotations(predictions, annotations):\n",
    "    #create the matrix\n",
    "    IoU_mat = np.zeros((len(predictions), len(annotations)))\n",
    "    # fill matrix with IoU values\n",
    "    for pred_idx, pred in enumerate(predictions):\n",
    "        for anno_idx, anno in enumerate(annotations):\n",
    "            IoU_mat[pred_idx, anno_idx] = IoU(pred, anno)\n",
    "    \n",
    "    # create output list\n",
    "    annotation_matches = []\n",
    "    if IoU_mat.size != 0:\n",
    "        max_idx = np.unravel_index(np.argmax(IoU_mat, axis=None), IoU_mat.shape)\n",
    "        max_IoU = IoU_mat[max_idx]\n",
    "        while max_IoU > 0:\n",
    "            # set the chosen rows and columns to 0\n",
    "            IoU_mat[max_idx[0],:] = 0\n",
    "            IoU_mat[:,max_idx[1]] = 0\n",
    "            # append the indices and IoU to result\n",
    "            annotation_matches.append((max_idx[0],max_idx[1],max_IoU))\n",
    "            max_idx = np.unravel_index(np.argmax(IoU_mat, axis=None), IoU_mat.shape)\n",
    "            max_IoU = IoU_mat[max_idx]\n",
    "    \n",
    "    return annotation_matches\n",
    "\n",
    "# Returns (T. Pos, F. Pos, F. Neg) for certain threshold\n",
    "def evaluate_bb(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    true_pos = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        i+=1\n",
    "        true_pos+=1\n",
    "    false_pos = len(predictions) - true_pos;\n",
    "    false_neg = len(annotations) - true_pos;\n",
    "    return true_pos, false_pos, false_neg\n",
    "\n",
    "# Returns the sum of angle errors and squared sum of angle errors for true positives\n",
    "# Errors are assumed in degrees\n",
    "def evaluate_angle(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    angle_err = 0\n",
    "    angle_err_sqr = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        pred_idx, anno_idx = annotation_matches[i][0:-1]\n",
    "        diff = annotations[anno_idx] - predictions[pred_idx]\n",
    "        diff = min(abs(diff), abs(diff-180), abs(diff+180)) # makes sure that the sigularity does not skew the results. Assumes degrees\n",
    "        angle_err += diff\n",
    "        angle_err_sqr += diff**2\n",
    "        i+=1\n",
    "    return angle_err, angle_err_sqr\n",
    "\n",
    "def evaluate_center_point(predictions, annotations, annotation_matches, threshold):\n",
    "    i = 0\n",
    "    center_pt_err = 0\n",
    "    center_pt_err_sqr = 0\n",
    "    while (i < len(annotation_matches)) and (annotation_matches[i][2]>threshold):\n",
    "        pred_idx, anno_idx = annotation_matches[i][0:-1]\n",
    "        pred_center_x = (predictions[pred_idx][0]+predictions[pred_idx][2])/2\n",
    "        pred_center_y = (predictions[pred_idx][1]+predictions[pred_idx][3])/2\n",
    "        anno_center_x = (annotations[anno_idx][0]+annotations[anno_idx][2])/2\n",
    "        anno_center_y = (annotations[anno_idx][1]+annotations[anno_idx][3])/2     \n",
    "        diff = np.sqrt((pred_center_x - anno_center_x)**2 + (pred_center_y - anno_center_y)**2) \n",
    "        center_pt_err += diff\n",
    "        center_pt_err_sqr += diff**2\n",
    "        i+=1\n",
    "    return center_pt_err, center_pt_err_sqr\n",
    "\n",
    "# finds annotation matches and calls evaluate_bb and evaluate_angle for several IoU-thresholds\n",
    "# ongoing_results is a tuple (total_T_pos, total_F_pos, total_F_neg, angle_err_sum, angle_err_sqr_sum)\n",
    "def evaluate_range(ongoing_results, box_preds, angle_preds, box_annos, angle_annos, thresholds):\n",
    "    annotation_matches = match_annotations(box_preds, box_annos)\n",
    "    for idx, thresh in enumerate(thresholds):\n",
    "        true_pos, false_pos, false_neg = evaluate_bb(box_preds, box_annos, annotation_matches, thresh)\n",
    "        angle_err, angle_err_sqr = evaluate_angle(angle_preds, angle_annos, annotation_matches, thresh)\n",
    "        center_pt_err, center_pt_err_sqr = evaluate_center_point(box_preds, box_annos, annotation_matches, thresh)\n",
    "        ongoing_results[idx][0] += true_pos \n",
    "        ongoing_results[idx][1] += false_pos\n",
    "        ongoing_results[idx][2] += false_neg\n",
    "        ongoing_results[idx][3] += angle_err\n",
    "        ongoing_results[idx][4] += angle_err_sqr\n",
    "        ongoing_results[idx][5] += center_pt_err\n",
    "        ongoing_results[idx][6] += center_pt_err_sqr\n",
    "        \n",
    "    return ongoing_results\n",
    "\n",
    "#Returns tuple (thresh, prec, rec, f1, avg_ang_err, std_ang_err, avg_center_err, std_center_err, t_pos, f_pos, f_neg)\n",
    "def get_result(final_results, thresholds):\n",
    "    result = []\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    avg_avg_ang_err = 0\n",
    "    avg_std_ang_err = 0\n",
    "    avg_avg_center_err = 0\n",
    "    avg_std_center_err = 0\n",
    "    for final_res, thresh in zip(final_results, thresholds):\n",
    "        precision = final_res[0]/(final_res[0]+final_res[1])\n",
    "        recall = final_res[0]/(final_res[0]+final_res[2])\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "        avg_ang_err = final_res[3]/final_res[0]\n",
    "        std_ang_err = np.sqrt((final_res[4]/final_res[0])-(avg_ang_err**2))\n",
    "        avg_center_err = final_res[5]/final_res[0]\n",
    "        std_center_err = np.sqrt((final_res[6]/final_res[0])-(avg_center_err**2))\n",
    "        result.append((thresh,precision, recall, f1, avg_ang_err, std_ang_err, avg_center_err, std_center_err, final_res[0], final_res[1], final_res[2]))\n",
    "        avg_prec += precision\n",
    "        avg_rec += recall\n",
    "        avg_avg_ang_err += avg_ang_err\n",
    "        avg_std_ang_err += std_ang_err\n",
    "        avg_avg_center_err += avg_center_err\n",
    "        avg_std_center_err += std_center_err\n",
    "    # append the average at the end \n",
    "    l = len(thresholds)\n",
    "    result.append(('Avg', avg_prec/l, avg_rec/l, 2*avg_prec/l*avg_rec/l/(avg_prec/l+avg_rec/l), avg_avg_ang_err/l, avg_std_ang_err/l,avg_avg_center_err/l, avg_std_center_err/l, '--','--','--'))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(folder, name, results, time):\n",
    "    with open(folder + name, 'w') as f:\n",
    "        f.write('IoU, Prec., Rec., F1, ang. err., std. ang. err., cent. err., std. cent. err. ,F. Neg, F. Pos, T. Pos \\n')\n",
    "        for result in results:\n",
    "            f.write(str(result[0])+', '+str(result[1])+', '+str(result[2])+', '+str(result[3])+', '+str(result[4])+', '+str(result[5])+ ', '+str(result[6])+', '+str(result[7])+', '+str(result[10])+', '+str(result[9])+', '+str(result[8])+'\\n')\n",
    "        f.write('Time: '+str(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-22.627417, -11.313708,  22.627417,  11.313708],\n",
      "       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n",
      "       [-35.918785, -17.959393,  35.918785,  17.959393],\n",
      "       [-16.      , -16.      ,  16.      ,  16.      ],\n",
      "       [-20.158737, -20.158737,  20.158737,  20.158737],\n",
      "       [-25.398417, -25.398417,  25.398417,  25.398417],\n",
      "       [-11.313708, -22.627417,  11.313708,  22.627417],\n",
      "       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n",
      "       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-45.254833, -22.627417,  45.254833,  22.627417],\n",
      "       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n",
      "       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n",
      "       [-32.      , -32.      ,  32.      ,  32.      ],\n",
      "       [-40.317474, -40.317474,  40.317474,  40.317474],\n",
      "       [-50.796833, -50.796833,  50.796833,  50.796833],\n",
      "       [-22.627417, -45.254833,  22.627417,  45.254833],\n",
      "       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n",
      "       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
      "       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n",
      "       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n",
      "       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n",
      "       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n",
      "       [-101.593666, -101.593666,  101.593666,  101.593666],\n",
      "       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n",
      "       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n",
      "       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n",
      "      dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n",
      "       [-228.07008, -114.03504,  228.07008,  114.03504],\n",
      "       [-287.35028, -143.67514,  287.35028,  143.67514],\n",
      "       [-128.     , -128.     ,  128.     ,  128.     ],\n",
      "       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n",
      "       [-203.18733, -203.18733,  203.18733,  203.18733],\n",
      "       [ -90.50967, -181.01933,   90.50967,  181.01933],\n",
      "       [-114.03504, -228.07008,  114.03504,  228.07008],\n",
      "       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-362.03867, -181.01933,  362.03867,  181.01933],\n",
      "       [-456.14017, -228.07008,  456.14017,  228.07008],\n",
      "       [-574.70056, -287.35028,  574.70056,  287.35028],\n",
      "       [-256.     , -256.     ,  256.     ,  256.     ],\n",
      "       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n",
      "       [-406.37466, -406.37466,  406.37466,  406.37466],\n",
      "       [-181.01933, -362.03867,  181.01933,  362.03867],\n",
      "       [-228.07008, -456.14017,  228.07008,  456.14017],\n",
      "       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "model_path = os.path.join(model_folder, model_name);\n",
    "model = models.load_model(model_path, backbone_name='resnet50');\n",
    "\n",
    "# If model is not converted to inference model, use line below: \n",
    "model = models.convert_model(model);\n",
    "\n",
    "# Mapping of model output and classes\n",
    "labels_to_names = {0: 'Brick'};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "file = open(img_list_file)\n",
    "file_paths = list(file)\n",
    "#file_paths = file_paths[0:30]\n",
    "\n",
    "IoU_thresholds = np.arange(0.5,1,0.05)\n",
    "\n",
    "ongoing_results = np.zeros((len(IoU_thresholds),7))\n",
    "\n",
    "total_time = 0\n",
    "for path in file_paths:\n",
    "    image = read_image_bgr(path_img_folder + path.strip('\\n'))\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    # preprocess image \n",
    "    # TODOD: check if preprocess_image convert the image to RGB format\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    # process image \n",
    "    boxes, scores, labels, angles = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    boxes, scores, labels, angles = filter_predictions(boxes[0], scores[0], labels[0], angles[0], 0.9)\n",
    "    angles = format_angles(angles, angle_rep)\n",
    "    end = time.perf_counter()\n",
    "    total_time += end-start\n",
    "    \n",
    "    ##load annotations\n",
    "    box_annos, angle_annos = read_annotations_from_json(path.strip('\\n'))\n",
    "    ongoing_results =  evaluate_range(ongoing_results, boxes, angles, box_annos, angle_annos, IoU_thresholds)\n",
    "final_results = get_result(ongoing_results, IoU_thresholds)\n",
    "write_results('./02 On Pallet Dataset/', model_name[0:-3]+'results_center.csv', final_results, total_time)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
