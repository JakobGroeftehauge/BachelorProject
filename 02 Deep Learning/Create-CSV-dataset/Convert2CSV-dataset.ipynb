{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert LabelMe Annotaiton to CSV-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from os import walk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "40\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "# Path the the folder containing the image annotations\n",
    "path = '../../03 Data/Simple Dataset/'\n",
    "validation_percent = 0.2\n",
    "\n",
    "#print(os.listdir(path))\n",
    "\n",
    "all_files = os.listdir(path)\n",
    "\n",
    "file_names = []\n",
    "for file in all_files: \n",
    "    if file[-5:]  == '.json':\n",
    "        file_names.append(file)\n",
    "    \n",
    "#print(file_names)\n",
    "random.shuffle(file_names)\n",
    "num_files = len(file_names)\n",
    "\n",
    "val_files = file_names[0:int(num_files*validation_percent)]\n",
    "train_files = file_names[int(num_files*validation_percent):]\n",
    "\n",
    "print(len(file_names))\n",
    "print(len(val_files))\n",
    "print(len(train_files))\n",
    "\n",
    "names = ['train_set4.csv', 'val_set4.csv']\n",
    "combined_files = [train_files, val_files]\n",
    "\n",
    "# create csv of train-set and val-set for feeding to the network\n",
    "for i in range(len(names)):\n",
    "    with open(names[i], 'w', newline='') as open_file:\n",
    "        writer = csv.writer(open_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        with open('list_of_img_in_'+names[i], 'w') as f:\n",
    "            for file in combined_files[i]:\n",
    "                with open(path + file) as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                    image_name = data['imagePath']\n",
    "                    f.write(\"%s\\n\" % image_name)\n",
    "                        # check if image contains annotations.\n",
    "                    if len(data['shapes']) != 0:\n",
    "                        for annotation in data['shapes']:\n",
    "                                rect = cv.boundingRect(np.float32(annotation['points']))\n",
    "                                P1x = str(rect[0])\n",
    "                                P1y = str(rect[1])\n",
    "                                P2x = str(rect[0] + rect[2])\n",
    "                                P2y = str(rect[1] + rect[3])\n",
    "                                class_name = annotation['label']\n",
    "                                writer.writerow([path + image_name, P1x, P1y, P2x, P2y, class_name])\n",
    "                    else:\n",
    "                        writer.writerow([path + image_name, \",,,,,\"])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
